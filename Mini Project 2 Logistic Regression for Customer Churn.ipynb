#!/usr/bin/env python
# coding: utf-8

# 
# Here's a basic outline you can follow to accomplish your task:
# 
# Import Libraries: Import necessary libraries such as pandas, numpy, matplotlib, seaborn, and scikit-learn.
# 
# Load the Dataset: Use pandas to load the dataset into a DataFrame.
# 
# Exploratory Data Analysis (EDA):
# 
# Check the first few rows of the dataset.
# Check for missing values and handle them if any.
# Check the data types of columns and convert them if necessary.
# Explore the distribution of target variable (churn) and other relevant features using visualizations.
# Explore correlations between features.
# Data Preprocessing:
# 
# Convert categorical variables into numerical using techniques like one-hot encoding or label encoding.
# Split the data into training and testing sets.
# Model Building:
# 
# Import Logistic Regression model from scikit-learn.
# Instantiate the model.
# Train the model on the training data.
# Model Evaluation:
# 
# Predict churn on the test set.
# Evaluate the model using appropriate metrics such as accuracy, precision, recall, F1-score, and ROC curve.
# Plot confusion matrix and ROC curve.
# Hyperparameter Tuning (Optional):
# 
# Tune hyperparameters of the logistic regression model using techniques like GridSearchCV or RandomizedSearchCV.
# Conclusion:
# 
# Summarize the findings.
# Provide recommendations based on the analysis.
# Documentation:
# 
# Add comments and explanations throughout the notebook to make it understandable to others.
# Include markdown cells with explanations of each step.
# Presentation:
# 
# Add visualizations to enhance the presentation of your findings.
# Write clear and concise explanations.
# Use markdown cells to format the text neatly.

# Here's a basic implementation of Logistic Regression for Customer Churn prediction in Python using scikit-learn along with the necessary libraries:

# In[ ]:


# Importing libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve

# Load the dataset
data = pd.read_csv("customer_churn_dataset.csv")

# Exploratory Data Analysis (EDA)
print(data.head())
print(data.info())
print(data.describe())

# Check for missing values
print(data.isnull().sum())

# Visualize the target variable
sns.countplot(x='Churn', data=data)

# Convert categorical variables to numerical
data = pd.get_dummies(data, drop_first=True)

# Splitting the dataset
X = data.drop('Churn_Yes', axis=1)
y = data['Churn_Yes']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Feature Scaling
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Model Building
model = LogisticRegression()
model.fit(X_train, y_train)

# Model Evaluation
y_pred = model.predict(X_test)
conf_matrix = confusion_matrix(y_test, y_pred)
print(conf_matrix)

print(classification_report(y_test, y_pred))

# ROC Curve
y_pred_proba = model.predict_proba(X_test)[:,1]
fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)
plt.plot(fpr, tpr, label='Logistic Regression (AUC = %0.2f)' % roc_auc_score(y_test, y_pred_proba))
plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend(loc='lower right')
plt.show()


# Make sure to replace "customer_churn_dataset.csv" with the actual path to your dataset file. This code assumes that your dataset contains a column named "Churn" indicating churn status, where 'Yes' means churned and 'No' means not churned. Adjust the code accordingly if your dataset has different column names or formats.
# 
# This code performs basic data preprocessing, builds a logistic regression model, evaluates it using confusion matrix, classification report, and ROC curve, and visualizes the ROC curve. You can further extend it by adding hyperparameter tuning or any other enhancements you see fit.
